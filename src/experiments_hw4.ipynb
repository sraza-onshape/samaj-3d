{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Fun with Point Clouds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Point Cloud Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Harris Corner Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: allow Jupyter to \"hot reload\" the modules we import - after each change, rerun this cell (instead of restarting the kernel!!)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from util import ops\n",
    "from util.corner_detection import HarrisCornerDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../hw4_data/problem1/rgb1.png',\n",
       " '../hw4_data/problem1/rgb2.png',\n",
       " '../hw4_data/problem1/rgb3.png']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_paths = sorted(glob.glob(\"../hw4_data/problem1/rgb*\"))\n",
    "rgb_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of ../hw4_data/problem1/rgb1.png: 480 x 640\n",
      "Dimensions of ../hw4_data/problem1/rgb2.png: 480 x 640\n",
      "Dimensions of ../hw4_data/problem1/rgb3.png: 480 x 640\n"
     ]
    }
   ],
   "source": [
    "illumination_images = [\n",
    "    ops.load_image(\n",
    "        path,\n",
    "        return_grayscale=True,\n",
    "        return_array=True\n",
    "    )\n",
    "    for path in rgb_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, let's map the filename of each RGB image, to the image itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's also load in the depth map images in a similar fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../hw4_data/problem1/depth1.png',\n",
       " '../hw4_data/problem1/depth2.png',\n",
       " '../hw4_data/problem1/depth3.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depthmap_paths = sorted(glob.glob(\"../hw4_data/problem1/depth*\"))\n",
    "depthmap_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of ../hw4_data/problem1/depth1.png: 480 x 640\n",
      "Dimensions of ../hw4_data/problem1/depth2.png: 480 x 640\n",
      "Dimensions of ../hw4_data/problem1/depth3.png: 480 x 640\n"
     ]
    }
   ],
   "source": [
    "depthmaps = [\n",
    "    ops.load_image(\n",
    "        path,\n",
    "        return_grayscale=True,\n",
    "        return_array=True\n",
    "    )\n",
    "    for path in depthmap_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Feature that Will Be Used to Fuse Point Clouds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by setting the hyperparameters given in in the hw 4 description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative_operator_x = np.array([\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "])\n",
    "derivative_operator_y = derivative_operator_x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the Gaussian filter provided here: https://homepages.inf.ed.ac.uk/rbf/HIPR2/gsmooth.htm\n",
    "gaussian_window = np.array([\n",
    "    [1, 4, 7, 4, 1],\n",
    "    [4, 16, 26, 16, 4],\n",
    "    [7, 26, 41, 26, 7],\n",
    "    [4, 16, 26, 16, 4],\n",
    "    [1, 4, 7, 4, 1],\n",
    "])\n",
    "\n",
    "gaussian_window = gaussian_window * (1 / 273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES_TO_SELECT = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's go ahead and apply the Harris Corner detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image_and_corners = dict()\n",
    "\n",
    "detector = HarrisCornerDetector()\n",
    "\n",
    "for rgb_path, image in zip(rgb_paths, illumination_images):\n",
    "\n",
    "    corner_response = detector.detect_features(\n",
    "        image,\n",
    "        use_non_max_suppression=True,\n",
    "        derivative_operator_x=derivative_operator_x,\n",
    "        derivative_operator_y=derivative_operator_y,\n",
    "        gaussian_window=gaussian_window,\n",
    "    )\n",
    "    # pick top features\n",
    "    top_k_points = detector.pick_top_features(\n",
    "        corner_response,\n",
    "        NUM_FEATURES_TO_SELECT\n",
    "    )\n",
    "\n",
    "    path_to_image_and_corners[rgb_path] = (image, top_k_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Corners to 3D Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by setting the hyperparameters given in in the hw 4 description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_matrix = K = np.array([\n",
    "    [525.,    0, 319.5],\n",
    "    [0,    525., 239.5],\n",
    "    [0,       0,     1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can project out the 3D points corresponding to the detected corners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "def convert_1_corner_to_3d(\n",
    "        xy_and_depth: tuple[int, int, float],\n",
    "        K: np.ndarray,\n",
    "        S: int,\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Follows the equation given in the hw 4 description.\n",
    "\n",
    "    Assumes the depth is not 0.\n",
    "\n",
    "    Parameters:\n",
    "        xy_and_depth(tuple): pixel coordinates and depth\n",
    "            of a detected corner\n",
    "        K(np.ndarray): 3x3 camera intrinsic matrix\n",
    "        S(int)\n",
    "\n",
    "    Returns: np.array - a row vector representing 3D worldspace\n",
    "        coordinates of the corner\n",
    "    \"\"\"\n",
    "    x, y, depth_val = xy_and_depth\n",
    "\n",
    "    image_coordinates_homogenous = np.array([x, y, 1]).T\n",
    "    worldspace_coordinates = (\n",
    "        (1 / S)  * depth_val * (linalg.inv(K) @ image_coordinates_homogenous)\n",
    "    )\n",
    "\n",
    "    assert worldspace_coordinates.shape == (3,)\n",
    "\n",
    "    return worldspace_coordinates.reshape(1, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this function across all the corners, in all the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_3d_points = dict()\n",
    "\n",
    "for image_index, image_path in enumerate(rgb_paths):\n",
    "\n",
    "     # per image, convert appropiate corners to 3d points\n",
    "     _, top_k_points = path_to_image_and_corners[image_path]\n",
    "     top_k_points = top_k_points.astype(int)\n",
    "     corresponding_depthmap = depthmaps[image_index]\n",
    "     depth_vals = corresponding_depthmap[\n",
    "          top_k_points[:, 0],\n",
    "          top_k_points[:, 1]\n",
    "     ].reshape(-1, 1)\n",
    "\n",
    "     world_space_coordinates_per_image = list()\n",
    "\n",
    "     for depth_val_index, depth_val in enumerate(depth_vals):\n",
    "          if depth_val != 0:\n",
    "               x, y = (\n",
    "                    top_k_points[depth_val_index, 1],\n",
    "                    top_k_points[depth_val_index, 0],\n",
    "               )\n",
    "               world_space_coord = convert_1_corner_to_3d(\n",
    "                    (x, y, depth_val),\n",
    "                    K,\n",
    "                    S,\n",
    "               )\n",
    "               world_space_coordinates_per_image.append(world_space_coord)\n",
    "\n",
    "     path_to_3d_points[image_path] = np.asarray(world_space_coordinates_per_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
