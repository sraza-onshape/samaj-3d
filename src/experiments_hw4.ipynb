{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Fun with Point Clouds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Point Cloud Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Harris Corner Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# optional: allow Jupyter to \"hot reload\" the modules we import - after each change, rerun this cell (instead of restarting the kernel!!)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from util import ops\n",
    "from util.corner_detection import HarrisCornerDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../hw4_data/problem1/rgb1.png',\n",
       " '../hw4_data/problem1/rgb2.png',\n",
       " '../hw4_data/problem1/rgb3.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_paths = sorted(glob.glob(\"../hw4_data/problem1/rgb*\"))\n",
    "rgb_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of ../hw4_data/problem1/rgb1.png: 480 x 640 x 3\n",
      "Dimensions of ../hw4_data/problem1/rgb2.png: 480 x 640 x 3\n",
      "Dimensions of ../hw4_data/problem1/rgb3.png: 480 x 640 x 3\n"
     ]
    }
   ],
   "source": [
    "rgb_images = [\n",
    "    ops.load_image(\n",
    "        path,\n",
    "        return_grayscale=False,\n",
    "        return_array=True\n",
    "    )\n",
    "    for path in rgb_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, let's map the filename of each RGB image, to the image itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's also load in the depth map images in a similar fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../hw4_data/problem1/depth1.png',\n",
       " '../hw4_data/problem1/depth2.png',\n",
       " '../hw4_data/problem1/depth3.png']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depthmap_paths = sorted(glob.glob(\"../hw4_data/problem1/depth*\"))\n",
    "depthmap_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of ../hw4_data/problem1/depth1.png: 480 x 640\n",
      "Dimensions of ../hw4_data/problem1/depth2.png: 480 x 640\n",
      "Dimensions of ../hw4_data/problem1/depth3.png: 480 x 640\n"
     ]
    }
   ],
   "source": [
    "depthmap_paths = [\n",
    "    ops.load_image(\n",
    "        path,\n",
    "        return_grayscale=True,\n",
    "        return_array=True\n",
    "    )\n",
    "    for path in depthmap_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Feature that Will Be Used to Fuse Point Clouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative_operator_x = np.array([\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "])\n",
    "derivative_operator_y = derivative_operator_x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the Gaussian filter provided here: https://homepages.inf.ed.ac.uk/rbf/HIPR2/gsmooth.htm\n",
    "gaussian_window = np.array([\n",
    "    [1, 4, 7, 4, 1],\n",
    "    [4, 16, 26, 16, 4],\n",
    "    [7, 26, 41, 26, 7],\n",
    "    [4, 16, 26, 16, 4],\n",
    "    [1, 4, 7, 4, 1],\n",
    "])\n",
    "\n",
    "gaussian_window = gaussian_window * (1 / 273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m top_many_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rgb_path, rgb_image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(rgb_paths, rgb_images):\n\u001b[0;32m----> 8\u001b[0m     corner_response \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrgb_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_non_max_suppression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mderivative_operator_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mderivative_operator_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mderivative_operator_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mderivative_operator_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgaussian_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgaussian_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# pick top features\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     top_k_points \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mpick_top_features(\n\u001b[1;32m     17\u001b[0m         corner_response,\n\u001b[1;32m     18\u001b[0m         top_many_features\n\u001b[1;32m     19\u001b[0m     )\n",
      "File \u001b[0;32m~/repos/CS-532-3D-Computer-Vision/src/util/corner_detection.py:181\u001b[0m, in \u001b[0;36mHarrisCornerDetector.detect_features\u001b[0;34m(self, image, use_non_max_suppression, derivative_operator_x, derivative_operator_y, gaussian_window)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gaussian_window \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     gaussian_window \u001b[38;5;241m=\u001b[39m BaseGaussianFilter()\u001b[38;5;241m.\u001b[39mcreate_gaussian_filter()\n\u001b[1;32m    177\u001b[0m (\n\u001b[1;32m    178\u001b[0m     convolved_hessian_xx,\n\u001b[1;32m    179\u001b[0m     convolved_hessian_yy,\n\u001b[1;32m    180\u001b[0m     convolved_hessian_xy,\n\u001b[0;32m--> 181\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_derivatives_in_gaussian_window\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgaussian_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgaussian_window\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m corner_response \u001b[38;5;241m=\u001b[39m _compute_corner_response(\n\u001b[1;32m    185\u001b[0m     gaussian_window,\n\u001b[1;32m    186\u001b[0m     convolved_hessian_xx,\n\u001b[1;32m    187\u001b[0m     convolved_hessian_yy,\n\u001b[1;32m    188\u001b[0m     convolved_hessian_xy,\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_non_max_suppression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/CS-532-3D-Computer-Vision/src/util/corner_detection.py:69\u001b[0m, in \u001b[0;36mHarrisCornerDetector.detect_features.<locals>._compute_derivatives_in_gaussian_window\u001b[0;34m(image, gaussian_window)\u001b[0m\n\u001b[1;32m     45\u001b[0m (\n\u001b[1;32m     46\u001b[0m     second_order_derivator_x,\n\u001b[1;32m     47\u001b[0m     second_order_derivator_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     ),\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m image_list \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     67\u001b[0m (hessian_xx, hessian_yy, hessian_xy) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     68\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m---> 69\u001b[0m         \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond_order_derivator_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     ),\n\u001b[1;32m     73\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m     74\u001b[0m         ops\u001b[38;5;241m.\u001b[39mconvolution(\n\u001b[1;32m     75\u001b[0m             image_list, second_order_derivator_y, padding_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[1;32m     77\u001b[0m     ),\n\u001b[1;32m     78\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m     79\u001b[0m         ops\u001b[38;5;241m.\u001b[39mconvolution(\n\u001b[1;32m     80\u001b[0m             image_list, second_order_derivator_xy, padding_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m     ),\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# compute the second moment matrix in a Gaussian window around each pixel\u001b[39;00m\n\u001b[1;32m     86\u001b[0m (convolved_hessian_xx, convolved_hessian_yy, convolved_hessian_xy) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     87\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m     88\u001b[0m         ops\u001b[38;5;241m.\u001b[39mconvolution(hessian_xx, gaussian_window, padding_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m     ),\n\u001b[1;32m     96\u001b[0m )\n",
      "File \u001b[0;32m~/repos/CS-532-3D-Computer-Vision/src/util/ops.py:451\u001b[0m, in \u001b[0;36mconvolution\u001b[0;34m(image, filter, stride, padding_type)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs a convolution on an input image.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03mPadding is used to ensure the output had the same dims as the input.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03mReturns: np.array: a new RGB image\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m### DRIVER\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m image, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m convolved_channel \u001b[38;5;241m=\u001b[39m convolve_2D(image, \u001b[38;5;28mfilter\u001b[39m, stride)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m convolved_channel\n",
      "File \u001b[0;32m~/repos/CS-532-3D-Computer-Vision/src/util/ops.py:376\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(image, img_filter, stride, padding_type)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m image:\n\u001b[1;32m    375\u001b[0m     zeros \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(padding_dist_x \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)]\n\u001b[0;32m--> 376\u001b[0m     padded_row \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m     padded_image\u001b[38;5;241m.\u001b[39mappend(padded_row)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# add the rows (at the end) that are all 0  - TODO[Zain]: remove duplicated code later\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "rgb_path_to_image_and_corners = dict()\n",
    "\n",
    "detector = HarrisCornerDetector()\n",
    "top_many_features = 100\n",
    "\n",
    "for rgb_path, rgb_image in zip(rgb_paths, rgb_images):\n",
    "\n",
    "    corner_response = detector.detect_features(\n",
    "        rgb_image,\n",
    "        use_non_max_suppression=True,\n",
    "        derivative_operator_x=derivative_operator_x,\n",
    "        derivative_operator_y=derivative_operator_y,\n",
    "        gaussian_window=gaussian_window,\n",
    "    )\n",
    "    # pick top features\n",
    "    top_k_points = detector.pick_top_features(\n",
    "        corner_response,\n",
    "        top_many_features\n",
    "    )\n",
    "\n",
    "    rgb_path_to_image_and_corners[rgb_path] = (rgb_image, top_k_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
